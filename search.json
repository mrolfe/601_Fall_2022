[
  {
    "objectID": "posts/challenge8_instructions.html",
    "href": "posts/challenge8_instructions.html",
    "title": "Challenge 8 Instructions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge8_instructions.html#challenge-overview",
    "href": "posts/challenge8_instructions.html#challenge-overview",
    "title": "Challenge 8 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in multiple data sets, and describe the data set using both words and any supporting information (e.g., tables, etc)\ntidy data (as needed, including sanity checks)\nmutate variables as needed (including sanity checks)\njoin two or more data sets and analyze some aspect of the joined data\n\n(be sure to only include the category tags for the data you use!)"
  },
  {
    "objectID": "posts/challenge8_instructions.html#read-in-data",
    "href": "posts/challenge8_instructions.html#read-in-data",
    "title": "Challenge 8 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\nmilitary marriages ⭐⭐\nfaostat ⭐⭐\nrailroads ⭐⭐⭐\nfed_rate ⭐⭐⭐\ndebt ⭐⭐⭐\nus_hh ⭐⭐⭐⭐\nsnl ⭐⭐⭐⭐⭐\n\n\n\n\n\nBriefly describe the data"
  },
  {
    "objectID": "posts/challenge8_instructions.html#tidy-data-as-needed",
    "href": "posts/challenge8_instructions.html#tidy-data-as-needed",
    "title": "Challenge 8 Instructions",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\n\nAre there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\nDocument your work here."
  },
  {
    "objectID": "posts/challenge8_instructions.html#join-data",
    "href": "posts/challenge8_instructions.html#join-data",
    "title": "Challenge 8 Instructions",
    "section": "Join Data",
    "text": "Join Data\nBe sure to include a sanity check, and double-check that case count is correct!"
  },
  {
    "objectID": "posts/challenge1_solutions.html",
    "href": "posts/challenge1_solutions.html",
    "title": "Challenge 1 Solution",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE)"
  },
  {
    "objectID": "posts/challenge1_solutions.html#working-with-tabular-data",
    "href": "posts/challenge1_solutions.html#working-with-tabular-data",
    "title": "Challenge 1 Solution",
    "section": "Working with Tabular Data",
    "text": "Working with Tabular Data\nOur advanced datasets ( ⭐⭐⭐ and higher) are tabular data (i.e., tables) that are often published based on government sources or by other organizations. Tabular data is often made available in Excel format (.xls or .xlsx) and is formatted for ease of reading - but this can make it tricky to read into R and reshape into a usable dataset.\nReading in tabular data will follow the same general work flow or work process regardless of formatting differences. We will work through the steps in detail this week (and in future weeks as new datasets are introduced), but this is an outline of the basic process. Note that not every step is needed for every file.\n\nIdentify grouping variables and values to extract from the table\nIdentify formatting issues that need to be addressed or eliminated\nIdentify column issues to be addressed during data read-in\nChoose column names to allow pivoting or future analysis\nAddress issues in rows using filter (and stringr package)\nCreate or mutate new variables as required, using separate, pivot_longer, etc\n\n\nRailroad ⭐FAOSTAT ⭐⭐Wild Birds ⭐⭐⭐Railroad (xls) ⭐⭐⭐⭐\n\n\nIt is hard to get much information about the data source or contents from a .csv file - as compared to the formatted .xlsx version of the same data described below.\n\nRead the Data\n\n\nCode\nrailroad<-read_csv(\"_data/railroad_2012_clean_county.csv\")\n\n\nRows: 2930 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): state, county\ndbl (1): total_employees\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nrailroad\n\n\n\n\n  \n\n\n\nFrom inspection, we can that the three variables are named state, county, and total employees. Combined with the name of the fail, this appears to be the aggregated data on the number of employees working for the railroad in each county 2012. We assume that the 2930 cases - which are counties embedded within states1 - consist only of counties where there are railroad employees?\n\n\nCode\nrailroad%>%\n  select(state)%>%\n  n_distinct(.)\n\n\n[1] 53\n\n\nCode\nrailroad%>%\n  select(state)%>%\n  distinct()\n\n\n\n\n  \n\n\n\nWith a few simple commands, we can confirm that there are 53 “states” represented in the data. To identify the additional non-state areas (probably District of Columbia, plus some combination of Puerto Rico and/or overseas addresses), we can print out a list of unique state names.\n\n1: We can identify case variables because both are character variables, which in tidy lingo are grouping variables not values.\n\n\n\nOnce again, a .csv file lacks any of the additional information that might be present in a published Excel table. So, we know the data are likely to be about birds, but will we be looking at individual pet birds, prices of bird breeds sold in stores, the average flock size of wild birds - who knows!\nThe FAOSTAT*.csv files have some additional information - the FAO - which a Google search reveals to be the Food and Agriculture Association of the United Nations publishes country-level data regularly in a database called FAOSTAT. So my best guess at this point is that we are going to be looking at country-level estaimtes of the number of birds that are raised for eggs and poultry, but we will see if this is right by inspecting the data.\n\nRead the Data\n\n\nCode\nbirds<-read_csv(\"_data/birds.csv\")\n\n\nRows: 30977 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Domain Code, Domain, Area, Element, Item, Unit, Flag, Flag Description\ndbl (6): Area Code, Element Code, Item Code, Year Code, Year, Value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nbirds\n\n\n\n\n  \n\n\n\nCode\nchickens<-read_csv(\"_data/FAOSTAT_egg_chicken.csv\")\n\n\nRows: 38170 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Domain Code, Domain, Area, Element, Item, Unit, Flag, Flag Description\ndbl (6): Area Code, Element Code, Item Code, Year Code, Year, Value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nchickens\n\n\n\n\n  \n\n\n\nIt is pretty difficult to get a handle on what data are being captured by any of the FAOSTAT* (including the birds.csv) data sets simply from a quick scan of the tibble after read in. It was easy with the railroad data, but now we are going to have to work harder to describe exactly what comprises a case in these data and what values are present for each case. We can see that there are 30,970 rows in the birds data (and 38,170 rows in the chickens) - but this might not mean that there are 30,970 (or 38,170) cases because we aren’t sure what constitutes a case at this point.\n\n\nWhat is a case?\nOne approach to figuring out what constitutes a case is to identify the value variables and assume that what is leftover are the grouping variables. Unfortunately, there are six double variables (from the column descriptions that are automatically returned), and it appears that most of them are not grouping variables. For example, the variable “Area Code” is a double - but doesn’t appear to be a value that varies across rows. Thus, it is a grouping variable rather than a true value in tidy nomenclature. Similar issues can be found with Year and “Item Code” - both appear to be grouping variables. Ironically, it is the variable called Value which appears to the sole value in the data set - but what is it the value of?\nAnother approach to identifying a case is to look for variation (or lack of variation) in just the first few cases of the tibble. (Think of this as the basis for a minimal reproducible example.) In the first few cases, the variables of the first 10 cases appear to be identical until we get to Year and Year Code (which appear to be identical to each other.) So it appears that Value is varying by country-year - but perhaps also by information in one of the other variables. It also appears that many of the doubles are just numeric codes, so lets drop those variables to simplify (I’m going to drop down to just showing the birds data for now.)\n\n\nCode\nbirds.sm<-birds%>%\n  select(-contains(\"Code\"))\nbirds.sm\n\n\n\n\n  \n\n\n\nCode\nchickens.sm<-chickens%>%\n  select(-contains(\"Code\"))\n\n\n\n\nVisual Summary of Data Set\nBefore we go doing detailed cross-tabs to figure out where there is variation, lets do a high level summary of the dataset to see if - for example - there are multiple values in the Element variable - or if we only have a dataset with records containing estimates of Chicken Stocks (from Element + Item.)\nTo get a better grasp of the data, lets do a quick skim or summary of the dataset and see if we can find out more about our data at a glance. I am using the dfSummary function from the summarytools package -one of the more attractive ways to quickly summarise a dataset. I am using a few options to allow it to render directly to html.\n\n\nCode\nprint(summarytools::dfSummary(birds.sm,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\n\n\nData Frame Summary\nbirds.sm\nDimensions: 30977 x 9\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      Domain\n[character]\n      1. Live Animals\n      30977(100.0%)\n      \n      0\n(0.0%)\n    \n    \n      Area\n[character]\n      1. Africa2. Asia3. Eastern Asia4. Egypt5. Europe6. France7. Greece8. Myanmar9. Northern Africa10. South-eastern Asia[ 238 others ]\n      290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)290(0.9%)28077(90.6%)\n      \n      0\n(0.0%)\n    \n    \n      Element\n[character]\n      1. Stocks\n      30977(100.0%)\n      \n      0\n(0.0%)\n    \n    \n      Item\n[character]\n      1. Chickens2. Ducks3. Geese and guinea fowls4. Pigeons, other birds5. Turkeys\n      13074(42.2%)6909(22.3%)4136(13.4%)1165(3.8%)5693(18.4%)\n      \n      0\n(0.0%)\n    \n    \n      Year\n[numeric]\n      Mean (sd) : 1990.6 (16.7)min ≤ med ≤ max:1961 ≤ 1992 ≤ 2018IQR (CV) : 29 (0)\n      58 distinct values\n      \n      0\n(0.0%)\n    \n    \n      Unit\n[character]\n      1. 1000 Head\n      30977(100.0%)\n      \n      0\n(0.0%)\n    \n    \n      Value\n[numeric]\n      Mean (sd) : 99410.6 (720611.4)min ≤ med ≤ max:0 ≤ 1800 ≤ 23707134IQR (CV) : 15233 (7.2)\n      11495 distinct values\n      \n      1036\n(3.3%)\n    \n    \n      Flag\n[character]\n      1. *2. A3. F4. Im5. M\n      1494(7.4%)6488(32.1%)10007(49.5%)1213(6.0%)1002(5.0%)\n      \n      10773\n(34.8%)\n    \n    \n      Flag Description\n[character]\n      1. Aggregate, may include of2. Data not available3. FAO data based on imputat4. FAO estimate5. Official data6. Unofficial figure\n      6488(20.9%)1002(3.2%)1213(3.9%)10007(32.3%)10773(34.8%)1494(4.8%)\n      \n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.1)2022-09-21\n\n\n\nFinally - we have a much better grasp on what is going on. First, we know that all records in this data set are of the number of Live Animal Stocks (Domain + Element), with the value expressed as 1000 heads (Unit). These three variables are grouping variables but DO NOT vary in this particular data extract - but are probably used to create data extracts from the larger FAOSTAT database.. To see if we are correct, we will have to checkout the same fields in the chickens data below.\nSecond, we can now guess that a case consists of a country-year-animal record - as captured in the variables Area, Year and Item, respectively - estimate of the number of live animals (Value.) ALso, as a side note, it appears that the estimated number of animals may have a long right-hand tail - just looking at the mini-histogram. So we can now say that we have estimates of the stock of five different types of poultry (Chickens, Ducks, Geese and guinea fowls, Turkeys, and Pigeons/Others) in 248 areas (countries??) for 58 years between 1961-2018.\nThe only minor concern is that we are still not entirely sure what information is being captured in the Flag (and matching Flag Description) variable. It appears unlikely that there is more than one estimate per country-year-animal case (see the summary of Area where all countries have 290 observations.) An assumption of one type of estimate (the content of Flag Description) per year is also consistent with the histogram of Year, which is pretty consistent although more countries were clearly added later in the series and data collection is not complete for the most recent time period.\nWe can dig a bit more, and find the description of the Flag field on the FAOSTAT website.. Sure enough, this confirms that the flags correspond to what type of estimate is being used (e.g., official data vs an estimate by FAOSTAT or imputed data.)\nWe can also confirm that NOT all cases are countries, as there is a Flag value, A, described as aggregated data. A quick inspection of the areas using this flag confirm that all of the “countries” are actually regional aggregations, and should be filtered out of the dataset as they are not the same “type” of case as a country-level case. To fix these data into true tidy format, we would need to filter out the aggregates, then merge on the country group definitions from FAOSTAT to create new country-group or regional variables that could be used to recreate aggregated estimates with dplyr.\n\n\nCode\nbirds.sm%>%\n  filter(Flag==\"A\")%>%\n  group_by(Area)%>%\n  summarize(n=n())\n\n\n\n\n  \n\n\n\n\n\nFAOstat*.csv\nLets take a quick look at our chickens data to see if it follows the same basic pattern as the birds data. Sure enough, it looks like we have a different domain (livestock products) but that the cases remain similar country-year-product, with three slightly different estimates related to egg-laying (instead of the five types of poultry.)\n\n\nCode\nprint(summarytools::dfSummary(chickens.sm,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\n\n\nData Frame Summary\nchickens.sm\nDimensions: 38170 x 9\n  Duplicates: 0\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      Domain\n[character]\n      1. Livestock Primary\n      38170(100.0%)\n      \n      0\n(0.0%)\n    \n    \n      Area\n[character]\n      1. Afghanistan2. Africa3. Albania4. Algeria5. American Samoa6. Americas7. Angola8. Antigua and Barbuda9. Argentina10. Asia[ 235 others ]\n      174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)174(0.5%)36430(95.4%)\n      \n      0\n(0.0%)\n    \n    \n      Element\n[character]\n      1. Laying2. Production3. Yield\n      12679(33.2%)12840(33.6%)12651(33.1%)\n      \n      0\n(0.0%)\n    \n    \n      Item\n[character]\n      1. Eggs, hen, in shell\n      38170(100.0%)\n      \n      0\n(0.0%)\n    \n    \n      Year\n[numeric]\n      Mean (sd) : 1990.5 (16.7)min ≤ med ≤ max:1961 ≤ 1991 ≤ 2018IQR (CV) : 29 (0)\n      58 distinct values\n      \n      0\n(0.0%)\n    \n    \n      Unit\n[character]\n      1. 1000 Head2. 100mg/An3. tonnes\n      12679(33.2%)12651(33.1%)12840(33.6%)\n      \n      0\n(0.0%)\n    \n    \n      Value\n[numeric]\n      Mean (sd) : 291341.2 (2232761)min ≤ med ≤ max:1 ≤ 31996 ≤ 76769955IQR (CV) : 91235.8 (7.7)\n      21325 distinct values\n      \n      40\n(0.1%)\n    \n    \n      Flag\n[character]\n      1. *2. A3. F4. Fc5. Im6. M\n      1435(4.7%)3186(10.4%)10538(34.4%)13344(43.6%)2079(6.8%)40(0.1%)\n      \n      7548\n(19.8%)\n    \n    \n      Flag Description\n[character]\n      1. Aggregate, may include of2. Calculated data3. Data not available4. FAO data based on imputat5. FAO estimate6. Official data7. Unofficial figure\n      3186(8.3%)13344(35.0%)40(0.1%)2079(5.4%)10538(27.6%)7548(19.8%)1435(3.8%)\n      \n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.1)2022-09-21\n\n\n\n\n\n\nThe “wild_bird_data” sheet is in Excel format (.xlsx) instead of the .csv format of the earlier data sets. In theory, it should be no harder to read in an Excel worksheet (or even workbook) as compared to a .csv file - there is a package called read_xl that is part of the tidyverse that easily reads in excel files.\nHowever, in practice, most people use Excel sheets as a publication format - not a way to store data, so there is almost always a ton of “junk” in the file that is NOT part of the data table that we want to read in. Sometimes the additional “junk” is incredibly useful - it might include table notes or information about data sources. However, we still need a systematic way to identify this junk and get rid of it during the data reading step.\nFor example, lets see what happens here if we just read in the wild bird data straight from excel.\n\n\nCode\nwildbirds<-read_excel(\"_data/wild_bird_data.xlsx\")\nwildbirds\n\n\n\n\n  \n\n\n\nHm, this doesn’t seem quite right. It is clear that the first “case” has information in it that looks more like variable labels. Lets take a quick look at the raw data.\n\n\n\nWild Bird Excel File\n\n\nSure enough the Excel file first row does contain additional information, a pointer to the article that this data was drawn from, and a quick Google reveals the article is [Nee, S., Read, A., Greenwood, J. et al. The relationship between abundance and body size in British birds. Nature 351, 312–313 (1991)] (https://www.nature.com/articles/351312a0)\n\nSkipping a row\nWe could try to manually adjust things - remove the first row, change the column names, and then change the column types. But this is both a lot of work, and not really a best practice for data management. Lets instead re-read the data in with the skip option from read_excel, and see if it fixes all of our problems!\n\n\nCode\nwildbirds <- read_excel(\"_data/wild_bird_data.xlsx\",\n                        skip = 1)\nwildbirds\n\n\n\n\n  \n\n\n\nThis now looks great! Both variables are numeric, and now they correctly show up as double or (). The variable names might be a bit tough to work with, though, so it can be easier to assign new column names on the read in - and then manually adjust axis labels, etc once you are working on your publication-quality graphs.\nNote that I skip two rows this time, and apply my own column names.\n\n\nCode\nwildbirds <- read_excel(\"_data/wild_bird_data.xlsx\",\n                        skip = 2, \n                        col_names = c(\"weight\", \"pop_size\"))\nwildbirds\n\n\n\n\n  \n\n\n\n\n\n\nThe railroad data set is our most challenging data to read in this week, but is (by comparison) a fairly straightforward formatted table published by the Railroad Retirement Board. The value variable is a count of the number of employees in each county and state combination. \nLooking at the excel file, we can see that there are only a few issues: 1. There are three rows at the top of the sheet that are not needed 2. There are blank columns that are not needed. 3. There are Total rows for each state that are not needed\n\nSkipping title rows\nFor the first issue, we use the “skip” option on read_excel from the readxl package to skip the rows at the top.\n\n\nCode\nread_excel(\"_data/StateCounty2012.xls\",\n                     skip = 3)\n\n\nNew names:\n• `` -> `...2`\n• `` -> `...4`\n\n\n\n\n  \n\n\n\n\n\nRemoving empty columns\nFor the second issue, I name the blank columns “delete” to make is easy to remove the unwanted columns. I then use select (with the ! sign to designate the complement or NOT) to select columns we wish to keep in the dataset - the rest are removed. Note that I skip 4 rows this time as I do not need the original header row.\nThere are other approaches you could use for this task (e.g., remove all columns that have no valid volues), but hard coding of variable names and types during data read in is not considered a violation of best practices and - if used strategically - can often make later data cleaning much easier.\n\n\nCode\nread_excel(\"_data/StateCounty2012.xls\",\n                     skip = 4,\n                     col_names= c(\"State\", \"delete\", \"County\", \"delete\", \"Employees\"))%>%\n  select(!contains(\"delete\"))\n\n\nNew names:\n• `delete` -> `delete...2`\n• `delete` -> `delete...4`\n\n\n\n\n  \n\n\n\n\n\nFiltering “total” rows\nFor the third issue, we are going to use filter to identify (and drop the rows that have the word “Total” in the State column). str_detect can be used to find specific rows within a column that have the designated “pattern”, while the “!” designates the complement of the selected rows (i.e., those without the “pattern” we are searching for.)\nThe str_detect command is from the stringr package, and is a powerful and easy to use implementation of grep and regex in the tidyverse - the base R functions (grep, gsub, etc) are classic but far more difficult to use, particularly for those not in practice. Be sure to explore the stringr package on your own.\n\n\nCode\nrailroad<-read_excel(\"_data/StateCounty2012.xls\",\n                     skip = 4,\n                     col_names= c(\"State\", \"delete\", \"County\", \"delete\", \"Employees\"))%>%\n  select(!contains(\"delete\"))%>%\n  filter(!str_detect(State, \"Total\"))\n\n\nNew names:\n• `delete` -> `delete...2`\n• `delete` -> `delete...4`\n\n\nCode\nrailroad\n\n\n\n\n  \n\n\n\n\n\nRemove any table notes\nTables often have notes in the last few table rows. You can check table limits and use this information during data read-in to not read the notes by setting the n-max option at the total number of rows to read, or less commonly, the range option to specify the spreadsheet range in standard excel naming (e.g., “B4:R142”). If you didn’t handle this on read in, you can use the tail command to check for notes and either tail or head to keep only the rows that you need.\n\n\nCode\ntail(railroad, 10)\n\n\n\n\n  \n\n\n\nCode\n#remove the last two observations\nrailroad <-head(railroad, -2)\ntail(railroad, 10)\n\n\n\n\n  \n\n\n\n\n\nConfirm cases\nAnd that is all it takes! The data are now ready for analysis. Lets see if we get the same number of unique states that were in the cleaned data in exercise 1.\n\n\nCode\nrailroad%>%\n  select(State)%>%\n  n_distinct(.)\n\n\n[1] 54\n\n\nCode\nrailroad%>%\n  select(State)%>%\n  distinct()\n\n\n\n\n  \n\n\n\nOh my goodness! It seems that we have an additional “State” - it looks like Canada is in the full excel data and not the tidy data. This is one example of why it is good practice to always work from the original data source!"
  },
  {
    "objectID": "posts/challenge3_instructions.html",
    "href": "posts/challenge3_instructions.html",
    "title": "Challenge 3 Instructions",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge3_instructions.html#challenge-overview",
    "href": "posts/challenge3_instructions.html#challenge-overview",
    "title": "Challenge 3 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\nidentify what needs to be done to tidy the current data\nanticipate the shape of pivoted data\npivot the data into tidy format using pivot_longer"
  },
  {
    "objectID": "posts/challenge3_instructions.html#read-in-data",
    "href": "posts/challenge3_instructions.html#read-in-data",
    "title": "Challenge 3 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\nanimal_weights.csv ⭐\neggs_tidy.csv ⭐⭐ or organicpoultry.xls ⭐⭐⭐\naustralian_marriage*.xlsx ⭐⭐⭐\nUSA Households*.xlsx ⭐⭐⭐⭐\nsce_labor_chart_data_public.csv 🌟🌟🌟🌟🌟\n\n\n\n\n\nBriefly describe the data\nDescribe the data, and be sure to comment on why you are planning to pivot it to make it “tidy”"
  },
  {
    "objectID": "posts/challenge3_instructions.html#anticipate-the-end-result",
    "href": "posts/challenge3_instructions.html#anticipate-the-end-result",
    "title": "Challenge 3 Instructions",
    "section": "Anticipate the End Result",
    "text": "Anticipate the End Result\nThe first step in pivoting the data is to try to come up with a concrete vision of what the end product should look like - that way you will know whether or not your pivoting was successful.\nOne easy way to do this is to think about the dimensions of your current data (tibble, dataframe, or matrix), and then calculate what the dimensions of the pivoted data should be.\nSuppose you have a dataset with \\(n\\) rows and \\(k\\) variables. In our example, 3 of the variables are used to identify a case, so you will be pivoting \\(k-3\\) variables into a longer format where the \\(k-3\\) variable names will move into the names_to variable and the current values in each of those columns will move into the values_to variable. Therefore, we would expect \\(n * (k-3)\\) rows in the pivoted dataframe!\n\nExample: find current and future data dimensions\nLets see if this works with a simple example.\n\n\nCode\ndf<-tibble(country = rep(c(\"Mexico\", \"USA\", \"France\"),2),\n           year = rep(c(1980,1990), 3), \n           trade = rep(c(\"NAFTA\", \"NAFTA\", \"EU\"),2),\n           outgoing = rnorm(6, mean=1000, sd=500),\n           incoming = rlogis(6, location=1000, \n                             scale = 400))\ndf\n\n\n# A tibble: 6 × 5\n  country  year trade outgoing incoming\n  <chr>   <dbl> <chr>    <dbl>    <dbl>\n1 Mexico   1980 NAFTA     499.     40.5\n2 USA      1990 NAFTA     527.    -64.1\n3 France   1980 EU        735.    -14.2\n4 Mexico   1990 NAFTA    1264.   1312. \n5 USA      1980 NAFTA    1232.    965. \n6 France   1990 EU       1274.   1092. \n\n\nCode\n#existing rows/cases\nnrow(df)\n\n\n[1] 6\n\n\nCode\n#existing columns/cases\nncol(df)\n\n\n[1] 5\n\n\nCode\n#expected rows/cases\nnrow(df) * (ncol(df)-3)\n\n\n[1] 12\n\n\nCode\n# expected columns \n3 + 2\n\n\n[1] 5\n\n\nOr simple example has \\(n = 6\\) rows and \\(k - 3 = 2\\) variables being pivoted, so we expect a new dataframe to have \\(n * 2 = 12\\) rows x \\(3 + 2 = 5\\) columns.\n\n\nChallenge: Describe the final dimensions\nDocument your work here.\n\n\n\nAny additional comments?"
  },
  {
    "objectID": "posts/challenge3_instructions.html#pivot-the-data",
    "href": "posts/challenge3_instructions.html#pivot-the-data",
    "title": "Challenge 3 Instructions",
    "section": "Pivot the Data",
    "text": "Pivot the Data\nNow we will pivot the data, and compare our pivoted data dimensions to the dimensions calculated above as a “sanity” check.\n\nExample\n\n\nCode\ndf<-pivot_longer(df, col = c(outgoing, incoming),\n                 names_to=\"trade_direction\",\n                 values_to = \"trade_value\")\ndf\n\n\n# A tibble: 12 × 5\n   country  year trade trade_direction trade_value\n   <chr>   <dbl> <chr> <chr>                 <dbl>\n 1 Mexico   1980 NAFTA outgoing              499. \n 2 Mexico   1980 NAFTA incoming               40.5\n 3 USA      1990 NAFTA outgoing              527. \n 4 USA      1990 NAFTA incoming              -64.1\n 5 France   1980 EU    outgoing              735. \n 6 France   1980 EU    incoming              -14.2\n 7 Mexico   1990 NAFTA outgoing             1264. \n 8 Mexico   1990 NAFTA incoming             1312. \n 9 USA      1980 NAFTA outgoing             1232. \n10 USA      1980 NAFTA incoming              965. \n11 France   1990 EU    outgoing             1274. \n12 France   1990 EU    incoming             1092. \n\n\nYes, once it is pivoted long, our resulting data are \\(12x5\\) - exactly what we expected!\n\n\nChallenge: Pivot the Chosen Data\nDocument your work here. What will a new “case” be once you have pivoted the data? How does it meet requirements for tidy data?\n\n\n\nAny additional comments?"
  },
  {
    "objectID": "posts/challenge7_instructions.html",
    "href": "posts/challenge7_instructions.html",
    "title": "Challenge 7 Instructions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge7_instructions.html#challenge-overview",
    "href": "posts/challenge7_instructions.html#challenge-overview",
    "title": "Challenge 7 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\ntidy data (as needed, including sanity checks)\nmutate variables as needed (including sanity checks)\nRecreate at least two graphs from previous exercises, but introduce at least one additional dimension that you omitted before using ggplot functionality (color, shape, line, facet, etc) The goal is not to create unneeded chart ink (Tufte), but to concisely capture variation in additional dimensions that were collapsed in your earlier 2 or 3 dimensional graphs.\n\n\nExplain why you choose the specific graph type\n\n\nIf you haven’t tried in previous weeks, work this week to make your graphs “publication” ready with titles, captions, and pretty axis labels and other viewer-friendly features\n\nR Graph Gallery is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code. And anyone not familiar with Edward Tufte should check out his fantastic books and courses on data visualizaton.\n(be sure to only include the category tags for the data you use!)"
  },
  {
    "objectID": "posts/challenge7_instructions.html#read-in-data",
    "href": "posts/challenge7_instructions.html#read-in-data",
    "title": "Challenge 7 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\neggs ⭐\nabc_poll ⭐⭐\naustralian_marriage ⭐⭐\nhotel_bookings ⭐⭐⭐\nair_bnb ⭐⭐⭐\nus_hh ⭐⭐⭐⭐\nfaostat ⭐⭐⭐⭐⭐\n\n\n\n\n\nBriefly describe the data"
  },
  {
    "objectID": "posts/challenge7_instructions.html#tidy-data-as-needed",
    "href": "posts/challenge7_instructions.html#tidy-data-as-needed",
    "title": "Challenge 7 Instructions",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\n\nAre there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\nDocument your work here."
  },
  {
    "objectID": "posts/challenge7_instructions.html#visualization-with-multiple-dimensions",
    "href": "posts/challenge7_instructions.html#visualization-with-multiple-dimensions",
    "title": "Challenge 7 Instructions",
    "section": "Visualization with Multiple Dimensions",
    "text": "Visualization with Multiple Dimensions"
  },
  {
    "objectID": "posts/challenge2_solutions.html",
    "href": "posts/challenge2_solutions.html",
    "title": "Challenge 2 Solutions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readxl)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE,\n                      message=FALSE)"
  },
  {
    "objectID": "posts/challenge2_solutions.html#challenge-overview",
    "href": "posts/challenge2_solutions.html#challenge-overview",
    "title": "Challenge 2 Solutions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to\n\nread in a data set, and describe the data using both words and any supporting information (e.g., tables, etc)\nprovide summary statistics for different interesting groups within the data, and interpret those statistics\n\n\nRailroad ⭐FAOstat* ⭐⭐⭐Hotel Bookings ⭐⭐⭐⭐\n\n\nThe railroad data contain 2931 county-level aggregated counts of the number of railroad employees in 2012. Counties are embedded within States, and all 50 states plus Canada, overseas addresses in Asia and Europe, and Washington, DC are represented.\n\n\n\n\n\n\nData Summaries\n\n\n\nThis is a concise summary of more extensive work we did in Challenge 1, and is an example of how you should describe data in public-facing work. A “public-facing” version of your work contains all critical details needed to replicate your work, but doesn’t contain a point-by-point rundown of the mental process you went through to get to that point. (Your internal analysis file should probably walk through that mental process, however!)\n\n\n\nRead the data\nHere, we are just reusing the code from Challenge 1. We are using the excel version, to ensure that we get Canada, and are renaming the missing data in county for Canada so that we don’t accidently filter that observation out.\n\nrailroad<-read_excel(\"_data/StateCounty2012.xls\",\n                     skip = 4,\n                     col_names= c(\"state\", \"delete\",  \"county\",\n                                  \"delete\", \"employees\"))%>%\n  select(!contains(\"delete\"))%>%\n  filter(!str_detect(state, \"Total\"))\n\nrailroad<-head(railroad, -2)%>%\n  mutate(county = ifelse(state==\"CANADA\", \"CANADA\", county))\n\nrailroad\n\n\n\n  \n\n\n\n\n\nHow many values does X take on?\nNow, lets practice grouping our data and using other dplyr commands that make data wrangling super easy. First, lets take a closer look at how we counted the number of unique states last week. First, we selected the state column. Then we used the n_distinct command - which replicates the base R commands length(unique(var)).\n\n\n\n\n\n\nacross()\n\n\n\nInstead of counting the number of distinct values one at a time, I am doing an operation on two columns at the same time using across.\n\n\n\nrailroad%>%\n  summarise(across(c(state,county), n_distinct))\n\n\n\n  \n\n\n\nCheck this out - many counties have the same name! There are 2931 state-county cases, but only 1710 distinct county names. This is one reason it is so critical to understand “what is a case” when you are working with your data - otherwise you might accidentally collapse or group information that isn’t intended to be grouped.\n\n\nHow many total X are in group Y?\nSuppose we want to know the total number of railroad employees was in 2012, what is the best way to sum up all of the values in the data? The summarize function is useful for doing calculations across some or all of a data set.\n\nrailroad%>%\n  summarise(total_employees = sum(employees))\n\n\n\n  \n\n\n\nAround a quarter of a million people were employed in the railroad industry in 2012. While this may seem like a lot, it was a significant decrease in employment from a few decades earlier, according to official Bureau of Labor Statistics (BLS) estimates.\nYou may notice that the BLS estimates are significantly lower than the ones we are using, provided by the Railroad Retirement Board. Given that the Railroad Retirement Board has “gold-standard” data on railroad employees, this discrepancy suggests that many people who work in the railroad industry are being classified in a different way by BLS statistics.\n\n\nWhich X have the most Y?\nSuppose we are interested in which county names are duplicated most often, or in which states have the most railroad employees. We can use the same basic approach to answer both “Which X have the most Y?” style questions\n\n\n\n\n\n\ndf-print: paged (YAML)\n\n\n\nWhen you are using df-print: paged in your yaml header, or are using tibbles, there is no need to rely on the head(data) command to limit your results to the top 10 of a list.\n\n\n\nrailroad%>%\n  group_by(state)%>%\n  summarise(total_employees = sum(employees),\n            num_counties = n())%>%\n  arrange(desc(total_employees))\n\n\n\n  \n\n\n\nLooking at the top 10 states in terms of total railroad employment, a few trends emerge. Several of the top 10 states with geographical activity are highly populous and geographically large. California, Texas, New York, Pennsylvania, Ohio, Illinois, and Georgia are all amonst the top-10 largest states - so it would make sense if there are more railroad employees in large states.\nBut railroads are spread out along geography, and thus we might also expect square mileage within a state to be related to state railroad employment - not just state population. For example, Texas is around 65% larger (in area) than California, and has around 50% more railroad employees.\nThere appear to be multiple exceptions to both rules, however. If geography plus population were the primary factors explaining railroad employment, then California would be ranked higher than New York and Illinois, and New York would likely rank higher than Illinois. However, Illinois - Chicago in particular - is a hub of railroad activity, and thus Illinois’ higher ranking is likely reflecting hub activity and employment. New York is a hub for the East Coast in particular. While California may have hubs of train activity in Los Angeles or San Francisco, the Northeast has a higher density of train stations and almost certainly generates more passenger and freight miles than the larger and more populous California.\nThis final factor - the existence of heavily used train routes probably explains the high railroad employment in states like Nebraska, Indiana and Missouri - all of which lay along a major railway route between New York and Chicago, and then out to California. Anyway who has played Ticket to Ride probably recognizes many of these routes!\n\n\n\n\n\n\nGo further\n\n\n\nA fun exercise once you are comfortable with joins and map-based visualizatinos would be to join the railroad employment data to information about state population and geographic area, and also mapping information about railway routes, to get more insight into the factors driving railroad employment.\n\n\n\n\n\nThe FAOSTAT sheets are excerpts of the FAOSTAT database provided by the Food and Agriculture Association, an agency of the United Nations. We are using the file birds.csv that includes estimates of the stock of five different types of poultry (Chickens, Ducks, Geese and guinea fowls, Turkeys, and Pigeons/Others) for 248 areas for 58 years between 1961-2018. Estimated stocks are given in 1000 head.\nBecause we know (from challenge 1) that several of those areas include aggregated data (e.g., ) we are going to remove the aggregations, remove the unnecessary variables, and only work with the grouping variables available in the data. In a future challenge, we will join back on more data from the FAO to recreate regional groupings.\n\nbirds<-read_csv(\"_data/birds.csv\")%>%\n  select(-c(contains(\"Code\"), Element, Domain, Unit))%>%\n  filter(Flag!=\"A\")\nbirds\n\n\n\n  \n\n\n\n\nWhat is the average of Y for X groups?\nLets suppose we are starting off and know nothing about poultry stocks around the world, where could we start? Perhaps we could try to get a sense of the relative sizes of stocks of each of the five types of poultry, identified in the variable Item. Additionally, because some of the values may be missing, lets find out how many of the estimates are missing.\n\nbirds%>%\n  group_by(Item)%>%\n  summarise(avg_stocks = mean(Value, na.rm=TRUE),\n            med_stocks = median(Value, na.rm=TRUE),\n            n_missing = sum(is.na(Value)))\n\n\n\n  \n\n\n\nOn average, we can see that countries have far more chickens as livestock (\\(\\bar{x}\\)=58.4million head) than other livestock birds (average stocks range between 2 and 10 million head). However, the information from the median stock counts suggest that there is significant variation across countries along with a strong right hand skew with regards to chicken stocks. The median number of chickens in a country is 3.8 million head - significantly less than the mean of almost 60 million. Overall, missing data doesn’t seem to be a huge issue, so we will just use na.rm=TRUE and not worry too much about the missingness for now.\nIt could be that stock head counts have changed over time, so lets try selecting two points in time and seeing whether or not average livestock counts are changing.\n\n\n\n\n\n\npivot-wider\n\n\n\nIt can be difficult to visually report data in tidy format. For example, it is tough to compare two values when they are on different rows. In this example, I use pivot-wider to swap a tidy grouping variable into multiple columns to be more “table-like.” I then do some manual formatting to make it easy to compare the grouped estimates.\n\n\n\nt1<-birds%>%\n  filter(Year %in% c(1966, 2016))%>%\n  group_by(Year, Item)%>%\n  summarise(avg_stocks = mean(Value, na.rm=TRUE),\n            med_stocks = median(Value, na.rm=TRUE))%>%\n  pivot_wider(names_from = Year, values_from = c(avg_stocks, med_stocks))\n\nknitr::kable(t1,\n             digits=0,format.args = list(big.mark = \",\"),\n             col.names = c(\"Type\", \"1966\", \"2016\",\n                           \"1996\", \"2016\"))%>%\n  kableExtra::kable_styling(htmltable_class = \"lightable-minimal\")%>%\n  kableExtra::add_header_above(c(\" \" = 1, \"Mean Stock (1000)\" = 2,\n                                 \"Median Stock (1000)\" = 2))\n\n\n\n \n\n\nMean Stock (1000)\nMedian Stock (1000)\n\n  \n    Type \n    1966 \n    2016 \n    1996 \n    2016 \n  \n \n\n  \n    Chickens \n    25,264 \n    105,437 \n    2,315 \n    7,854 \n  \n  \n    Ducks \n    5,053 \n    14,842 \n    110 \n    236 \n  \n  \n    Geese and guinea fowls \n    2,468 \n    11,750 \n    97 \n    73 \n  \n  \n    Pigeons, other birds \n    3,314 \n    2,874 \n    3,000 \n    1,194 \n  \n  \n    Turkeys \n    843 \n    2,858 \n    74 \n    194 \n  \n\n\n\n\n\n\n\n\n\n\n\nkable and kableExtra\n\n\n\nI manually adjust table formatting (column names, setting significant digits, adding a comma) using kable and add a header row using kableExtra. Because df-print=paged option is set to make it easier to scroll through longer data frames, I need to directly specify that I want to produce an htmltable - not a default kable/rmarkdown table - when I use kable and kableExtra formatting directly.\n\n\nSure enough, it does look like stocks have changed significantly over time. The expansion of country-level chicken stocks over five decades between 1966 and 2016 are most noteworthy, with both average and median stock count going up by a factor of 4. Pigeons have never been very popular, and average stocks have actually decreased over the same time period while the other less popular bird - turkeys - saw significant incrases in stock count. Some countries increased specialization in goose and/or guinea fowl production, as the average stock count went up but the median went down over the same period.\n\n\n\n\n\n\nGo further\n\n\n\nIt could be really interesting to graph the rise and fall of poultry stocks overtime with these data, and match these changes to changes in population size and country GDP. Another option would be to match the countries back to regional groupings available from the UN FAO, a future “data join” challenge.\n\n\n\n\n\nThis data set contains 119,390 hotel bookings from two hotels (“City Hotel” and “Resort Hotel”) with an arrival date between July 2015 and August 2017 (more detail needed), including bookings that were later cancelled. Each row contains extensive information about a single booking:\n\nthe booking process (e.g., lead time, booking agent, deposit, changes made)\nbooking details (e.g., scheduled arrival date, length of stay)\nguest requests (e.g., type of room, meal(s) included, car parking)\nbooking channel (e.g., distribution, market segment, corporate affiliation for )\nguest information (e.g., child/adult, passport country)\nguest prior bookings (e.g., repeat customer, prior cancellations)\n\nThe data are a de-identified extract of real hotel demand data, made available by the authors.\n\nRead and make sense of the data\nThe hotel bookings data set is new to challenge 2, so we need to go through the same process we did during challenge 1 to find out more about the data. Lets read in the data and use the summmaryTools package to get an overview of the data set.\n\nbookings<-read_csv(\"_data/hotel_bookings.csv\")\n\nprint(summarytools::dfSummary(bookings,\n                        varnumbers = FALSE,\n                        plain.ascii  = FALSE, \n                        style        = \"grid\", \n                        graph.magnif = 0.70, \n                        valid.col    = FALSE),\n      method = 'render',\n      table.classes = 'table-condensed')\n\n\n\nData Frame Summary\nbookings\nDimensions: 119390 x 32\n  Duplicates: 31994\n\n\n  \n    \n      Variable\n      Stats / Values\n      Freqs (% of Valid)\n      Graph\n      Missing\n    \n  \n  \n    \n      hotel\n[character]\n      1. City Hotel2. Resort Hotel\n      79330(66.4%)40060(33.6%)\n      \n      0\n(0.0%)\n    \n    \n      is_canceled\n[numeric]\n      Min  : 0Mean : 0.4Max  : 1\n      0:75166(63.0%)1:44224(37.0%)\n      \n      0\n(0.0%)\n    \n    \n      lead_time\n[numeric]\n      Mean (sd) : 104 (106.9)min ≤ med ≤ max:0 ≤ 69 ≤ 737IQR (CV) : 142 (1)\n      479 distinct values\n      \n      0\n(0.0%)\n    \n    \n      arrival_date_year\n[numeric]\n      Mean (sd) : 2016.2 (0.7)min ≤ med ≤ max:2015 ≤ 2016 ≤ 2017IQR (CV) : 1 (0)\n      2015:21996(18.4%)2016:56707(47.5%)2017:40687(34.1%)\n      \n      0\n(0.0%)\n    \n    \n      arrival_date_month\n[character]\n      1. August2. July3. May4. October5. April6. June7. September8. March9. February10. November[ 2 others ]\n      13877(11.6%)12661(10.6%)11791(9.9%)11160(9.3%)11089(9.3%)10939(9.2%)10508(8.8%)9794(8.2%)8068(6.8%)6794(5.7%)12709(10.6%)\n      \n      0\n(0.0%)\n    \n    \n      arrival_date_week_number\n[numeric]\n      Mean (sd) : 27.2 (13.6)min ≤ med ≤ max:1 ≤ 28 ≤ 53IQR (CV) : 22 (0.5)\n      53 distinct values\n      \n      0\n(0.0%)\n    \n    \n      arrival_date_day_of_month\n[numeric]\n      Mean (sd) : 15.8 (8.8)min ≤ med ≤ max:1 ≤ 16 ≤ 31IQR (CV) : 15 (0.6)\n      31 distinct values\n      \n      0\n(0.0%)\n    \n    \n      stays_in_weekend_nights\n[numeric]\n      Mean (sd) : 0.9 (1)min ≤ med ≤ max:0 ≤ 1 ≤ 19IQR (CV) : 2 (1.1)\n      17 distinct values\n      \n      0\n(0.0%)\n    \n    \n      stays_in_week_nights\n[numeric]\n      Mean (sd) : 2.5 (1.9)min ≤ med ≤ max:0 ≤ 2 ≤ 50IQR (CV) : 2 (0.8)\n      35 distinct values\n      \n      0\n(0.0%)\n    \n    \n      adults\n[numeric]\n      Mean (sd) : 1.9 (0.6)min ≤ med ≤ max:0 ≤ 2 ≤ 55IQR (CV) : 0 (0.3)\n      14 distinct values\n      \n      0\n(0.0%)\n    \n    \n      children\n[numeric]\n      Mean (sd) : 0.1 (0.4)min ≤ med ≤ max:0 ≤ 0 ≤ 10IQR (CV) : 0 (3.8)\n      0:110796(92.8%)1:4861(4.1%)2:3652(3.1%)3:76(0.1%)10:1(0.0%)\n      \n      4\n(0.0%)\n    \n    \n      babies\n[numeric]\n      Mean (sd) : 0 (0.1)min ≤ med ≤ max:0 ≤ 0 ≤ 10IQR (CV) : 0 (12.3)\n      0:118473(99.2%)1:900(0.8%)2:15(0.0%)9:1(0.0%)10:1(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      meal\n[character]\n      1. BB2. FB3. HB4. SC5. Undefined\n      92310(77.3%)798(0.7%)14463(12.1%)10650(8.9%)1169(1.0%)\n      \n      0\n(0.0%)\n    \n    \n      country\n[character]\n      1. PRT2. GBR3. FRA4. ESP5. DEU6. ITA7. IRL8. BEL9. BRA10. NLD[ 168 others ]\n      48590(40.7%)12129(10.2%)10415(8.7%)8568(7.2%)7287(6.1%)3766(3.2%)3375(2.8%)2342(2.0%)2224(1.9%)2104(1.8%)18590(15.6%)\n      \n      0\n(0.0%)\n    \n    \n      market_segment\n[character]\n      1. Aviation2. Complementary3. Corporate4. Direct5. Groups6. Offline TA/TO7. Online TA8. Undefined\n      237(0.2%)743(0.6%)5295(4.4%)12606(10.6%)19811(16.6%)24219(20.3%)56477(47.3%)2(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      distribution_channel\n[character]\n      1. Corporate2. Direct3. GDS4. TA/TO5. Undefined\n      6677(5.6%)14645(12.3%)193(0.2%)97870(82.0%)5(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      is_repeated_guest\n[numeric]\n      Min  : 0Mean : 0Max  : 1\n      0:115580(96.8%)1:3810(3.2%)\n      \n      0\n(0.0%)\n    \n    \n      previous_cancellations\n[numeric]\n      Mean (sd) : 0.1 (0.8)min ≤ med ≤ max:0 ≤ 0 ≤ 26IQR (CV) : 0 (9.7)\n      15 distinct values\n      \n      0\n(0.0%)\n    \n    \n      previous_bookings_not_canceled\n[numeric]\n      Mean (sd) : 0.1 (1.5)min ≤ med ≤ max:0 ≤ 0 ≤ 72IQR (CV) : 0 (10.9)\n      73 distinct values\n      \n      0\n(0.0%)\n    \n    \n      reserved_room_type\n[character]\n      1. A2. B3. C4. D5. E6. F7. G8. H9. L10. P\n      85994(72.0%)1118(0.9%)932(0.8%)19201(16.1%)6535(5.5%)2897(2.4%)2094(1.8%)601(0.5%)6(0.0%)12(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      assigned_room_type\n[character]\n      1. A2. D3. E4. F5. G6. C7. B8. H9. I10. K[ 2 others ]\n      74053(62.0%)25322(21.2%)7806(6.5%)3751(3.1%)2553(2.1%)2375(2.0%)2163(1.8%)712(0.6%)363(0.3%)279(0.2%)13(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      booking_changes\n[numeric]\n      Mean (sd) : 0.2 (0.7)min ≤ med ≤ max:0 ≤ 0 ≤ 21IQR (CV) : 0 (2.9)\n      21 distinct values\n      \n      0\n(0.0%)\n    \n    \n      deposit_type\n[character]\n      1. No Deposit2. Non Refund3. Refundable\n      104641(87.6%)14587(12.2%)162(0.1%)\n      \n      0\n(0.0%)\n    \n    \n      agent\n[character]\n      1. 92. NULL3. 2404. 15. 146. 77. 68. 2509. 24110. 28[ 324 others ]\n      31961(26.8%)16340(13.7%)13922(11.7%)7191(6.0%)3640(3.0%)3539(3.0%)3290(2.8%)2870(2.4%)1721(1.4%)1666(1.4%)33250(27.8%)\n      \n      0\n(0.0%)\n    \n    \n      company\n[character]\n      1. NULL2. 403. 2234. 675. 456. 1537. 1748. 2199. 28110. 154[ 343 others ]\n      112593(94.3%)927(0.8%)784(0.7%)267(0.2%)250(0.2%)215(0.2%)149(0.1%)141(0.1%)138(0.1%)133(0.1%)3793(3.2%)\n      \n      0\n(0.0%)\n    \n    \n      days_in_waiting_list\n[numeric]\n      Mean (sd) : 2.3 (17.6)min ≤ med ≤ max:0 ≤ 0 ≤ 391IQR (CV) : 0 (7.6)\n      128 distinct values\n      \n      0\n(0.0%)\n    \n    \n      customer_type\n[character]\n      1. Contract2. Group3. Transient4. Transient-Party\n      4076(3.4%)577(0.5%)89613(75.1%)25124(21.0%)\n      \n      0\n(0.0%)\n    \n    \n      adr\n[numeric]\n      Mean (sd) : 101.8 (50.5)min ≤ med ≤ max:-6.4 ≤ 94.6 ≤ 5400IQR (CV) : 56.7 (0.5)\n      8879 distinct values\n      \n      0\n(0.0%)\n    \n    \n      required_car_parking_spaces\n[numeric]\n      Mean (sd) : 0.1 (0.2)min ≤ med ≤ max:0 ≤ 0 ≤ 8IQR (CV) : 0 (3.9)\n      0:111974(93.8%)1:7383(6.2%)2:28(0.0%)3:3(0.0%)8:2(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      total_of_special_requests\n[numeric]\n      Mean (sd) : 0.6 (0.8)min ≤ med ≤ max:0 ≤ 0 ≤ 5IQR (CV) : 1 (1.4)\n      0:70318(58.9%)1:33226(27.8%)2:12969(10.9%)3:2497(2.1%)4:340(0.3%)5:40(0.0%)\n      \n      0\n(0.0%)\n    \n    \n      reservation_status\n[character]\n      1. Canceled2. Check-Out3. No-Show\n      43017(36.0%)75166(63.0%)1207(1.0%)\n      \n      0\n(0.0%)\n    \n    \n      reservation_status_date\n[Date]\n      min : 2014-10-17med : 2016-08-07max : 2017-09-14range : 2y 10m 28d\n      926 distinct values\n      \n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.1)2022-09-21\n\n\n\nWow - there is a lot of information available here. Lets scan it and see what jumps out. First we can see that the summary function claims that there are almost 32,000 duplicates in the data. However, this is likely an artifact of the way that the bookings have been de-identified, and may reflect bookings with identical details but different individuals who made the bookings.\nWe can see that we are provided with limited information about the hotel. Hotels are identified only as “City” Hotel” or a “Resort Hotel”. Maybe we have bookings from only two hotels? Lets tentatively add that to our data description.\nThere is a flag for whether a booking is cancelled. This means that our universe of cases includes bookings where the guests showed up, as well as bookings that were later cancelled - we can add that to our data description.\nThere are multiple fields with the arrival date - year, month, etc. For now, we can tell that the arrival date of the bookings ranges between 2015 and 2017. More precise identification of the date range could be more easily done next challenge when we can recode the arrival date information using lubridate.But maybe it is possible to find out which values of month co-occur with specific years?\n\n\nWhich values of Y are nested within X?\nTo approach this question, we can narrow the dataset down to just the two variables of interest, and then use the distinct command.\n\nbookings%>%\n  select(arrival_date_year, arrival_date_month)%>%\n  distinct()\n\n\n\n  \n\n\n\nGreat - now we now that all bookings have arrival dates between June 2015 and August 2017, and can add that to the data description. Just for fun, lets see if we can confirm that the dates are the same for both hotels.\n\n\n\n\n\n\nslice()\n\n\n\nThis would be easier to investigate with proper date variables, but I am using slice to find the first and last row for each hotel, by position. This avoids printing out a long data list we have to scroll through, but would fail if the hotels had different sets of arrival month-year pairs.\n\n\n\nd<-bookings%>%\n  select(arrival_date_year, arrival_date_month)%>%\n  n_distinct\n\nbookings%>%\n  select(hotel, arrival_date_year, arrival_date_month)%>%\n  distinct()%>%\n  slice(c(1, d, d+1, d*2))\n\n\n\n  \n\n\n\nLets suppose we want to know whether or not the two hotels offer the same types of rooms? This is another query of the sort Which values of X are nested in y?\n\nbookings%>%\n  group_by(hotel)%>%\n  count(reserved_room_type)\n\n\n\n  \n\n\n\nIn this case, however, it is tough to directly compare - it appears that the hotel-roomtype pairs are not as consistent as the year-month pairs for the same hotels. A quick pivot-wider makes this comparison a little easier to visualize. Here we can see that the Resort Hotel has two additional room types: “H” and “L”.\n\nbookings%>%\n  group_by(hotel)%>%\n  count(reserved_room_type)%>%\n  pivot_wider(names_from= hotel, values_from = n)\n\n\n\n  \n\n\n\n\n\nWhat is the average of Y for group X?\nThe breakdown of rooms by hotel doesn’t shed much light on the room codes and what they might mean. Lets see if we can find average number of occupants and average price for each room type, and see if we can learn more about our data.\n\n\n\n\n\n\nmean(., na.rm=TRUE)\n\n\n\nI am using the mean function with the option na.rm=TRUE to deal with the four NA values in the children field, identified in the summary table above.\n\n\n\nt1<-bookings%>%\n  group_by(hotel, reserved_room_type)%>%\n  summarise(price = mean(adr),\n            adults = mean(adults),\n            children = mean(children+babies, na.rm=TRUE)\n            )%>%\n  pivot_wider(names_from= hotel, \n              values_from = c(price, adults, children))\n\nknitr::kable(t1,\n             digits=1,\n             col.names = c(\"Type\", \"City\", \"Resort\",\n                           \"City\", \"Resort\", \"City\", \"Resort\"))%>%\n  kableExtra::kable_styling(htmltable_class = \"lightable-minimal\")%>%\n  kableExtra::add_header_above(c(\"Room\" = 1, \"Price\" = 2,\n                                 \"Adults\" = 2, \"Children & Babies\" = 2))\n\n\nAverage Price and Occupancy, by hotel and room type\n \n\nRoom\nPrice\nAdults\nChildren & Babies\n\n  \n    Type \n    City \n    Resort \n    City \n    Resort \n    City \n    Resort \n  \n \n\n  \n    A \n    96.2 \n    76.2 \n    1.8 \n    1.8 \n    0.0 \n    0.0 \n  \n  \n    B \n    90.3 \n    104.7 \n    1.6 \n    2.0 \n    0.6 \n    0.0 \n  \n  \n    C \n    85.5 \n    161.4 \n    1.5 \n    2.0 \n    0.1 \n    1.4 \n  \n  \n    D \n    131.5 \n    103.6 \n    2.2 \n    2.0 \n    0.0 \n    0.1 \n  \n  \n    E \n    156.8 \n    114.5 \n    2.1 \n    2.0 \n    0.3 \n    0.0 \n  \n  \n    F \n    189.3 \n    132.8 \n    2.0 \n    2.0 \n    1.6 \n    0.1 \n  \n  \n    G \n    201.8 \n    168.2 \n    2.3 \n    2.0 \n    1.1 \n    1.4 \n  \n  \n    P \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n    0.0 \n  \n  \n    H \n    NA \n    188.2 \n    NA \n    2.7 \n    NA \n    1.0 \n  \n  \n    L \n    NA \n    124.7 \n    NA \n    2.2 \n    NA \n    0.0 \n  \n\n\n\n\n\n\n\n\n\n\n\nkable & kableExtra\n\n\n\nI manually adjust table formatting (column names, plus adding a header row) using kable and kableExtra package, respectively. Also, because df-print=paged is the option set in the YAML header, I need to directly specify that I want to produce an htmltable - not a default kable/rmarkdown table.\n\n\nBased on these descriptives broken down by hotel and room type, we can speculate that the “H” and “L” room types at the resort are likely some sort of multi-bedroom suite (because the average number of adults is over 2.) Similarly, we can speculate that the difference between ABC and DEF may be something related to room size or quality (e.g., number and size of beds) and/or related to meals included with the rooms - but this would require further investigation to pin down!\n\n\n\n\n\n\nGo further\n\n\n\nThere is lots more to explore in the hotel bookings dataset, but it will be a lot easier once we recode the date fields using lubridate."
  },
  {
    "objectID": "posts/challenge2_instructions.html",
    "href": "posts/challenge2_instructions.html",
    "title": "Challenge 2 Instructions",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge2_instructions.html#challenge-overview",
    "href": "posts/challenge2_instructions.html#challenge-overview",
    "title": "Challenge 2 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to\n\nread in a data set, and describe the data using both words and any supporting information (e.g., tables, etc)\nprovide summary statistics for different interesting groups within the data, and interpret those statistics"
  },
  {
    "objectID": "posts/challenge2_instructions.html#read-in-the-data",
    "href": "posts/challenge2_instructions.html#read-in-the-data",
    "title": "Challenge 2 Instructions",
    "section": "Read in the Data",
    "text": "Read in the Data\nRead in one (or more) of the following data sets, available in the posts/_data folder, using the correct R package and command.\n\nrailroad*.csv or StateCounty2012.xlsx ⭐\nFAOstat*.csv ⭐⭐⭐\nhotel_bookings ⭐⭐⭐⭐\n\n\n\n\nAdd any comments or documentation as needed. More challenging data may require additional code chunks and documentation."
  },
  {
    "objectID": "posts/challenge2_instructions.html#describe-the-data",
    "href": "posts/challenge2_instructions.html#describe-the-data",
    "title": "Challenge 2 Instructions",
    "section": "Describe the data",
    "text": "Describe the data\nUsing a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data)."
  },
  {
    "objectID": "posts/challenge2_instructions.html#provide-grouped-summary-statistics",
    "href": "posts/challenge2_instructions.html#provide-grouped-summary-statistics",
    "title": "Challenge 2 Instructions",
    "section": "Provide Grouped Summary Statistics",
    "text": "Provide Grouped Summary Statistics\nConduct some exploratory data analysis, using dplyr commands such as group_by(), select(), filter(), and summarise(). Find the central tendency (mean, median, mode) and dispersion (standard deviation, mix/max/quantile) for different subgroups within the data set.\n\n\n\n\nExplain and Interpret\nBe sure to explain why you choose a specific group. Comment on the interpretation of any interesting differences between groups that you uncover. This section can be integrated with the exploratory data analysis, just be sure it is included."
  },
  {
    "objectID": "posts/challenge6_instructions.html",
    "href": "posts/challenge6_instructions.html",
    "title": "Challenge 6 Instructions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge6_instructions.html#challenge-overview",
    "href": "posts/challenge6_instructions.html#challenge-overview",
    "title": "Challenge 6 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\ntidy data (as needed, including sanity checks)\nmutate variables as needed (including sanity checks)\ncreate at least one graph including time (evolution)\n\n\ntry to make them “publication” ready (optional)\nExplain why you choose the specific graph type\n\n\nCreate at least one graph depicting part-whole or flow relationships\n\n\ntry to make them “publication” ready (optional)\nExplain why you choose the specific graph type\n\nR Graph Gallery is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code.\n(be sure to only include the category tags for the data you use!)"
  },
  {
    "objectID": "posts/challenge6_instructions.html#read-in-data",
    "href": "posts/challenge6_instructions.html#read-in-data",
    "title": "Challenge 6 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\ndebt ⭐\nfed_rate ⭐⭐\nabc_poll ⭐⭐⭐\nusa_hh ⭐⭐⭐\nhotel_bookings ⭐⭐⭐⭐\nair_bnb ⭐⭐⭐⭐⭐\n\n\n\n\n\nBriefly describe the data"
  },
  {
    "objectID": "posts/challenge6_instructions.html#tidy-data-as-needed",
    "href": "posts/challenge6_instructions.html#tidy-data-as-needed",
    "title": "Challenge 6 Instructions",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\n\nAre there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\nDocument your work here."
  },
  {
    "objectID": "posts/challenge6_instructions.html#time-dependent-visualization",
    "href": "posts/challenge6_instructions.html#time-dependent-visualization",
    "title": "Challenge 6 Instructions",
    "section": "Time Dependent Visualization",
    "text": "Time Dependent Visualization"
  },
  {
    "objectID": "posts/challenge6_instructions.html#visualizing-part-whole-relationships",
    "href": "posts/challenge6_instructions.html#visualizing-part-whole-relationships",
    "title": "Challenge 6 Instructions",
    "section": "Visualizing Part-Whole Relationships",
    "text": "Visualizing Part-Whole Relationships"
  },
  {
    "objectID": "posts/challenge1_instructions.html",
    "href": "posts/challenge1_instructions.html",
    "title": "Challenge 1 Instructions",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#challenge-overview",
    "href": "posts/challenge1_instructions.html#challenge-overview",
    "title": "Challenge 1 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to\n\nread in a dataset, and\ndescribe the dataset using both words and any supporting information (e.g., tables, etc)"
  },
  {
    "objectID": "posts/challenge1_instructions.html#read-in-the-data",
    "href": "posts/challenge1_instructions.html#read-in-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Read in the Data",
    "text": "Read in the Data\nRead in one (or more) of the following data sets, using the correct R package and command.\n\nrailroad_2012_clean_county.csv ⭐\nbirds.csv ⭐⭐\nFAOstat*.csv ⭐⭐\nwild_bird_data.xlsx ⭐⭐⭐\nStateCounty2012.xlsx ⭐⭐⭐⭐\n\nFind the _data folder, located inside the posts folder. Then you can read in the data, using either one of the readr standard tidy read commands, or a specialized package such as readxl.\n\n\n\nAdd any comments or documentation as needed. More challenging data sets may require additional code chunks and documentation."
  },
  {
    "objectID": "posts/challenge1_instructions.html#describe-the-data",
    "href": "posts/challenge1_instructions.html#describe-the-data",
    "title": "Challenge 1 Instructions",
    "section": "Describe the data",
    "text": "Describe the data\nUsing a combination of words and results of R commands, can you provide a high level description of the data? Describe as efficiently as possible where/how the data was (likely) gathered, indicate the cases and variables (both the interpretation and any details you deem useful to the reader to fully understand your chosen data)."
  },
  {
    "objectID": "posts/challenge5_instructions.html",
    "href": "posts/challenge5_instructions.html",
    "title": "Challenge 5 Instructions",
    "section": "",
    "text": "library(tidyverse)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge5_instructions.html#challenge-overview",
    "href": "posts/challenge5_instructions.html#challenge-overview",
    "title": "Challenge 5 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\ntidy data (as needed, including sanity checks)\nmutate variables as needed (including sanity checks)\ncreate at least two univariate visualizations\n\n\ntry to make them “publication” ready\nExplain why you choose the specific graph type\n\n\nCreate at least one bivariate visualization\n\n\ntry to make them “publication” ready\nExplain why you choose the specific graph type\n\nR Graph Gallery is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code.\n(be sure to only include the category tags for the data you use!)"
  },
  {
    "objectID": "posts/challenge5_instructions.html#read-in-data",
    "href": "posts/challenge5_instructions.html#read-in-data",
    "title": "Challenge 5 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\ncereal ⭐\npathogen cost ⭐\nAustralian Marriage ⭐⭐\nAB_NYC_2019.csv ⭐⭐⭐\nrailroads ⭐⭐⭐\nPublic School Characteristics ⭐⭐⭐⭐\nUSA Households ⭐⭐⭐⭐⭐\n\n\n\n\n\nBriefly describe the data"
  },
  {
    "objectID": "posts/challenge5_instructions.html#tidy-data-as-needed",
    "href": "posts/challenge5_instructions.html#tidy-data-as-needed",
    "title": "Challenge 5 Instructions",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\n\nAre there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\nDocument your work here."
  },
  {
    "objectID": "posts/challenge5_instructions.html#univariate-visualizations",
    "href": "posts/challenge5_instructions.html#univariate-visualizations",
    "title": "Challenge 5 Instructions",
    "section": "Univariate Visualizations",
    "text": "Univariate Visualizations"
  },
  {
    "objectID": "posts/challenge5_instructions.html#bivariate-visualizations",
    "href": "posts/challenge5_instructions.html#bivariate-visualizations",
    "title": "Challenge 5 Instructions",
    "section": "Bivariate Visualization(s)",
    "text": "Bivariate Visualization(s)\nAny additional comments?"
  },
  {
    "objectID": "posts/challenge4_instructions.html",
    "href": "posts/challenge4_instructions.html",
    "title": "Challenge 4 Instructions",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "posts/challenge4_instructions.html#challenge-overview",
    "href": "posts/challenge4_instructions.html#challenge-overview",
    "title": "Challenge 4 Instructions",
    "section": "Challenge Overview",
    "text": "Challenge Overview\nToday’s challenge is to:\n\nread in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\ntidy data (as needed, including sanity checks)\nidentify variables that need to be mutated\nmutate variables and sanity check all mutations"
  },
  {
    "objectID": "posts/challenge4_instructions.html#read-in-data",
    "href": "posts/challenge4_instructions.html#read-in-data",
    "title": "Challenge 4 Instructions",
    "section": "Read in data",
    "text": "Read in data\nRead in one (or more) of the following datasets, using the correct R package and command.\n\nabc_poll.csv ⭐\npoultry_tidy.csv⭐⭐\nFedFundsRate.csv⭐⭐⭐\nhotel_bookings.csv⭐⭐⭐⭐\ndebt_in_trillions ⭐⭐⭐⭐⭐\n\n\n\n\n\nBriefly describe the data"
  },
  {
    "objectID": "posts/challenge4_instructions.html#tidy-data-as-needed",
    "href": "posts/challenge4_instructions.html#tidy-data-as-needed",
    "title": "Challenge 4 Instructions",
    "section": "Tidy Data (as needed)",
    "text": "Tidy Data (as needed)\nIs your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here.\n\n\n\nAny additional comments?"
  },
  {
    "objectID": "posts/challenge4_instructions.html#identify-variables-that-need-to-be-mutated",
    "href": "posts/challenge4_instructions.html#identify-variables-that-need-to-be-mutated",
    "title": "Challenge 4 Instructions",
    "section": "Identify variables that need to be mutated",
    "text": "Identify variables that need to be mutated\nAre there any variables that require mutation to be usable in your analysis stream? For example, are all time variables correctly coded as dates? Are all string variables reduced and cleaned to sensible categories? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?\nDocument your work here.\n\n\n\nAny additional comments?"
  },
  {
    "objectID": "about/ProfRolfe.html",
    "href": "about/ProfRolfe.html",
    "title": "",
    "section": "",
    "text": "<!DOCTYPE html>\n\n\n\n     \n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDACSS_601_August2022_v2/ProfRolfe.qmd at template · mrolfe/DACSS_601_August2022_v2\n\n\n\n\n\n\n\n\n<meta name=\"google-site-verification\" content=\"c1kuD-K2HIVF635lypcsWPoD4kilo5-jA_wBFyT4uMY\">\n\n\n\n\n\n\n\n\n<meta name=\"user-login\" content=\"mrolfe\">\n\n<meta name=\"viewport\" content=\"width=device-width\">\n\n  <meta name=\"description\" content=\"DACSS August 2022 Blog. Contribute to mrolfe/DACSS_601_August2022_v2 development by creating an account on GitHub.\">\n  <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/opensearch.xml\" title=\"GitHub\">\n<link rel=\"fluid-icon\" href=\"https://github.com/fluidicon.png\" title=\"GitHub\">\n<meta property=\"fb:app_id\" content=\"1401488693436528\">\n<meta name=\"apple-itunes-app\" content=\"app-id=1477376905\" />\n  <meta name=\"twitter:image:src\" content=\"https://opengraph.githubassets.com/3bef214981806d3d6467439c0388de54b70ba3bec32aad08ce8a523aa9a408c0/mrolfe/DACSS_601_August2022_v2\" /><meta name=\"twitter:site\" content=\"@github\" /><meta name=\"twitter:card\" content=\"summary_large_image\" /><meta name=\"twitter:title\" content=\"DACSS_601_August2022_v2/ProfRolfe.qmd at template · mrolfe/DACSS_601_August2022_v2\" /><meta name=\"twitter:description\" content=\"DACSS August 2022 Blog. Contribute to mrolfe/DACSS_601_August2022_v2 development by creating an account on GitHub.\" />\n  <meta property=\"og:image\" content=\"https://opengraph.githubassets.com/3bef214981806d3d6467439c0388de54b70ba3bec32aad08ce8a523aa9a408c0/mrolfe/DACSS_601_August2022_v2\" /><meta property=\"og:image:alt\" content=\"DACSS August 2022 Blog. Contribute to mrolfe/DACSS_601_August2022_v2 development by creating an account on GitHub.\" /><meta property=\"og:image:width\" content=\"1200\" /><meta property=\"og:image:height\" content=\"600\" /><meta property=\"og:site_name\" content=\"GitHub\" /><meta property=\"og:type\" content=\"object\" /><meta property=\"og:title\" content=\"DACSS_601_August2022_v2/ProfRolfe.qmd at template · mrolfe/DACSS_601_August2022_v2\" /><meta property=\"og:url\" content=\"https://github.com/mrolfe/DACSS_601_August2022_v2\" /><meta property=\"og:description\" content=\"DACSS August 2022 Blog. Contribute to mrolfe/DACSS_601_August2022_v2 development by creating an account on GitHub.\" />\n  \n<link rel=\"assets\" href=\"https://github.githubassets.com/\">\n  <link rel=\"shared-web-socket\" href=\"wss://alive.github.com/_sockets/u/25716048/ws?session=eyJ2IjoiVjMiLCJ1IjoyNTcxNjA0OCwicyI6OTQ4MjMyNDk4LCJjIjoxMDA4MzAyOTM2LCJ0IjoxNjYyNTk2MzAxfQ==--795aafedc290b767c2a4e4138fe6f06fd73b46a5a232420852fd17c92899d9e7\" data-refresh-url=\"/_alive\" data-session-id=\"9d8b366c30e8ae4637138fc0f8d7d91aa3a1eade1ea64d215c01392a98fa3835\">\n  <link rel=\"shared-web-socket-src\" href=\"/assets-cdn/worker/socket-worker-b87581f5816c.js\">\n\n\n    <meta name=\"hostname\" content=\"github.com\">\n\n\n  <meta name=\"keyboard-shortcuts-preference\" content=\"all\">\n  <script type=\"application/json\" id=\"memex_keyboard_shortcuts_preference\">\"all\"</script>\n\n    <meta name=\"expected-hostname\" content=\"github.com\">\n\n<meta name=\"enabled-features\" content=\"ACTIONS_MERGE_GROUP_ENABLED,IMAGE_METRIC_TRACKING,GEOJSON_AZURE_MAPS\">\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<link rel=\"canonical\" href=\"https://github.com/mrolfe/DACSS_601_August2022_v2/blob/template/about/ProfRolfe.qmd\" data-pjax-transient>\n\n\n\n\n  \n\n\n\n\n\n\n  <a href=\"#start-of-content\" class=\"p-3 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\">Skip to content</a>\n  <span data-view-component=\"true\" class=\"progress-pjax-loader js-pjax-loader-bar Progress position-fixed width-full\">\n<span style=\"width: 0%;\" data-view-component=\"true\" class=\"Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis\"></span>\n\n    <script crossorigin=\"anonymous\" defer=\"defer\" type=\"application/javascript\" src=\"https://github.githubassets.com/assets/vendors-node_modules_github_mini-throttle_dist_decorators_js-node_modules_github_command-pale-4090c9-7f4a07119d05.js\"></script>\n\n\n\n        <header class=\"Header js-details-container Details px-3 px-md-4 px-lg-5 flex-wrap flex-md-nowrap\" role=\"banner\" >\n\n<div class=\"Header-item mt-n1 mb-n1  d-none d-md-flex\">\n  <a\nclass=“Header-link” href=“https://github.com/” data-hotkey=“g d” aria-label=“Homepage” data-turbo=“false” data-analytics-event=“{”category\":\"Header\",\"action\":\"go to dashboard\",\"label\":\"icon:logo\"}” >    \n</div>\n\n<div class=\"Header-item d-md-none\">\n    <button aria-label=\"Toggle navigation\" aria-expanded=\"false\" type=\"button\" data-view-component=\"true\" class=\"Header-link js-details-target btn-link\">    <svg aria-hidden=\"true\" height=\"24\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"24\" data-view-component=\"true\" class=\"octicon octicon-three-bars\">\n<path fill-rule=\"evenodd\" d=\"M1 2.75A.75.75 0 011.75 2h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 2.75zm0 5A.75.75 0 011.75 7h12.5a.75.75 0 110 1.5H1.75A.75.75 0 011 7.75zM1.75 12a.75.75 0 100 1.5h12.5a.75.75 0 100-1.5H1.75z\"></path>\n\n\n\n\n\n\n\n\n\n\n<!-- '\"` --><!-- </textarea></xmp> --></option></form><form class=\"js-site-search-form\" role=\"search\" aria-label=\"Site\" data-scope-type=\"Repository\" data-scope-id=\"527403483\" data-scoped-search-url=\"/mrolfe/DACSS_601_August2022_v2/search\" data-owner-scoped-search-url=\"/users/mrolfe/search\" data-unscoped-search-url=\"/search\" data-turbo=\"false\" action=\"/mrolfe/DACSS_601_August2022_v2/search\" accept-charset=\"UTF-8\" method=\"get\">\n  <label class=\"form-control input-sm header-search-wrapper p-0 js-chromeless-input-container header-search-wrapper-jump-to position-relative d-flex flex-justify-between flex-items-center\">\n    <input type=\"text\"\n      class=\"form-control input-sm header-search-input jump-to-field js-jump-to-field js-site-search-focus js-site-search-field is-clearable\"\n      data-hotkey=s,/\n      name=\"q\"\n      data-test-selector=\"nav-search-input\"\n      placeholder=\"Search or jump to…\"\n      data-unscoped-placeholder=\"Search or jump to…\"\n      data-scoped-placeholder=\"Search or jump to…\"\n      autocapitalize=\"off\"\n      role=\"combobox\"\n      aria-haspopup=\"listbox\"\n      aria-expanded=\"false\"\n      aria-autocomplete=\"list\"\n      aria-controls=\"jump-to-results\"\n      aria-label=\"Search or jump to…\"\n      data-jump-to-suggestions-path=\"/_graphql/GetSuggestedNavigationDestinations\"\n      spellcheck=\"false\"\n      autocomplete=\"off\"\n    >\n    <input type=\"hidden\" value=\"w3gdh6fuo33mVHQPviu_3RAzulao3Gm91hpCVitF2jhqkHkdPtX6g5V460yetwixwIT6Y_AJLhJ0TJjwtaWnrA\" data-csrf=\"true\" class=\"js-data-jump-to-suggestions-path-csrf\" />\n    <input type=\"hidden\" class=\"js-site-search-type-field\" name=\"type\" >\n        <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"22\" height=\"20\" aria-hidden=\"true\" class=\"mr-1 header-search-key-slash\"><path fill=\"none\" stroke=\"#979A9C\" opacity=\".4\" d=\"M3.5.5h12c1.7 0 3 1.3 3 3v13c0 1.7-1.3 3-3 3h-12c-1.7 0-3-1.3-3-3v-13c0-1.7 1.3-3 3-3z\"></path><path fill=\"#979A9C\" d=\"M11.8 6L8 15.1h-.9L10.8 6h1z\"></path></svg>\n\n\n      <div class=\"Box position-absolute overflow-hidden d-none jump-to-suggestions js-jump-to-suggestions-container\">\n        \n\n\n\n\n  <svg title=\"Repository\" aria-label=\"Repository\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo js-jump-to-octicon-repo d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z\"></path>\n\n  <svg title=\"Project\" aria-label=\"Project\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project js-jump-to-octicon-project d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M1.75 0A1.75 1.75 0 000 1.75v12.5C0 15.216.784 16 1.75 16h12.5A1.75 1.75 0 0016 14.25V1.75A1.75 1.75 0 0014.25 0H1.75zM1.5 1.75a.25.25 0 01.25-.25h12.5a.25.25 0 01.25.25v12.5a.25.25 0 01-.25.25H1.75a.25.25 0 01-.25-.25V1.75zM11.75 3a.75.75 0 00-.75.75v7.5a.75.75 0 001.5 0v-7.5a.75.75 0 00-.75-.75zm-8.25.75a.75.75 0 011.5 0v5.5a.75.75 0 01-1.5 0v-5.5zM8 3a.75.75 0 00-.75.75v3.5a.75.75 0 001.5 0v-3.5A.75.75 0 008 3z\"></path>\n\n  <svg title=\"Search\" aria-label=\"Search\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search js-jump-to-octicon-search d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z\"></path>\n\n</div>\n\n<img class=\"avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none\" alt=\"\" aria-label=\"Team\" src=\"\" width=\"28\" height=\"28\">\n\n<div class=\"jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target\">\n</div>\n\n<div class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none js-jump-to-badge-search\">\n  <span class=\"js-jump-to-badge-search-text-default d-none\" aria-label=\"in this repository\">\n    In this repository\n  </span>\n  <span class=\"js-jump-to-badge-search-text-global d-none\" aria-label=\"in all of GitHub\">\n    All GitHub\n  </span>\n  <span aria-hidden=\"true\" class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n<div aria-hidden=\"true\" class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump\">\n  Jump to\n  <span class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n\n\n\n\nNo suggested jump to results\n\n\n\n\n\n\n  <svg title=\"Repository\" aria-label=\"Repository\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo js-jump-to-octicon-repo d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z\"></path>\n\n  <svg title=\"Project\" aria-label=\"Project\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project js-jump-to-octicon-project d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M1.75 0A1.75 1.75 0 000 1.75v12.5C0 15.216.784 16 1.75 16h12.5A1.75 1.75 0 0016 14.25V1.75A1.75 1.75 0 0014.25 0H1.75zM1.5 1.75a.25.25 0 01.25-.25h12.5a.25.25 0 01.25.25v12.5a.25.25 0 01-.25.25H1.75a.25.25 0 01-.25-.25V1.75zM11.75 3a.75.75 0 00-.75.75v7.5a.75.75 0 001.5 0v-7.5a.75.75 0 00-.75-.75zm-8.25.75a.75.75 0 011.5 0v5.5a.75.75 0 01-1.5 0v-5.5zM8 3a.75.75 0 00-.75.75v3.5a.75.75 0 001.5 0v-3.5A.75.75 0 008 3z\"></path>\n\n  <svg title=\"Search\" aria-label=\"Search\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search js-jump-to-octicon-search d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z\"></path>\n\n</div>\n\n<img class=\"avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none\" alt=\"\" aria-label=\"Team\" src=\"\" width=\"28\" height=\"28\">\n\n<div class=\"jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target\">\n</div>\n\n<div class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none js-jump-to-badge-search\">\n  <span class=\"js-jump-to-badge-search-text-default d-none\" aria-label=\"in this repository\">\n    In this repository\n  </span>\n  <span class=\"js-jump-to-badge-search-text-global d-none\" aria-label=\"in all of GitHub\">\n    All GitHub\n  </span>\n  <span aria-hidden=\"true\" class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n<div aria-hidden=\"true\" class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump\">\n  Jump to\n  <span class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n\n\n\n\n  <svg title=\"Repository\" aria-label=\"Repository\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo js-jump-to-octicon-repo d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z\"></path>\n\n  <svg title=\"Project\" aria-label=\"Project\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project js-jump-to-octicon-project d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M1.75 0A1.75 1.75 0 000 1.75v12.5C0 15.216.784 16 1.75 16h12.5A1.75 1.75 0 0016 14.25V1.75A1.75 1.75 0 0014.25 0H1.75zM1.5 1.75a.25.25 0 01.25-.25h12.5a.25.25 0 01.25.25v12.5a.25.25 0 01-.25.25H1.75a.25.25 0 01-.25-.25V1.75zM11.75 3a.75.75 0 00-.75.75v7.5a.75.75 0 001.5 0v-7.5a.75.75 0 00-.75-.75zm-8.25.75a.75.75 0 011.5 0v5.5a.75.75 0 01-1.5 0v-5.5zM8 3a.75.75 0 00-.75.75v3.5a.75.75 0 001.5 0v-3.5A.75.75 0 008 3z\"></path>\n\n  <svg title=\"Search\" aria-label=\"Search\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search js-jump-to-octicon-search d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z\"></path>\n\n</div>\n\n<img class=\"avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none\" alt=\"\" aria-label=\"Team\" src=\"\" width=\"28\" height=\"28\">\n\n<div class=\"jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target\">\n</div>\n\n<div class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none js-jump-to-badge-search\">\n  <span class=\"js-jump-to-badge-search-text-default d-none\" aria-label=\"in this user\">\n    In this user\n  </span>\n  <span class=\"js-jump-to-badge-search-text-global d-none\" aria-label=\"in all of GitHub\">\n    All GitHub\n  </span>\n  <span aria-hidden=\"true\" class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n<div aria-hidden=\"true\" class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump\">\n  Jump to\n  <span class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n\n\n\n\n  <svg title=\"Repository\" aria-label=\"Repository\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-repo js-jump-to-octicon-repo d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M2 2.5A2.5 2.5 0 014.5 0h8.75a.75.75 0 01.75.75v12.5a.75.75 0 01-.75.75h-2.5a.75.75 0 110-1.5h1.75v-2h-8a1 1 0 00-.714 1.7.75.75 0 01-1.072 1.05A2.495 2.495 0 012 11.5v-9zm10.5-1V9h-8c-.356 0-.694.074-1 .208V2.5a1 1 0 011-1h8zM5 12.25v3.25a.25.25 0 00.4.2l1.45-1.087a.25.25 0 01.3 0L8.6 15.7a.25.25 0 00.4-.2v-3.25a.25.25 0 00-.25-.25h-3.5a.25.25 0 00-.25.25z\"></path>\n\n  <svg title=\"Project\" aria-label=\"Project\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-project js-jump-to-octicon-project d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M1.75 0A1.75 1.75 0 000 1.75v12.5C0 15.216.784 16 1.75 16h12.5A1.75 1.75 0 0016 14.25V1.75A1.75 1.75 0 0014.25 0H1.75zM1.5 1.75a.25.25 0 01.25-.25h12.5a.25.25 0 01.25.25v12.5a.25.25 0 01-.25.25H1.75a.25.25 0 01-.25-.25V1.75zM11.75 3a.75.75 0 00-.75.75v7.5a.75.75 0 001.5 0v-7.5a.75.75 0 00-.75-.75zm-8.25.75a.75.75 0 011.5 0v5.5a.75.75 0 01-1.5 0v-5.5zM8 3a.75.75 0 00-.75.75v3.5a.75.75 0 001.5 0v-3.5A.75.75 0 008 3z\"></path>\n\n  <svg title=\"Search\" aria-label=\"Search\" role=\"img\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search js-jump-to-octicon-search d-none flex-shrink-0\">\n<path fill-rule=\"evenodd\" d=\"M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z\"></path>\n\n</div>\n\n<img class=\"avatar mr-2 flex-shrink-0 js-jump-to-suggestion-avatar d-none\" alt=\"\" aria-label=\"Team\" src=\"\" width=\"28\" height=\"28\">\n\n<div class=\"jump-to-suggestion-name js-jump-to-suggestion-name flex-auto overflow-hidden text-left no-wrap css-truncate css-truncate-target\">\n</div>\n\n<div class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none js-jump-to-badge-search\">\n  <span class=\"js-jump-to-badge-search-text-default d-none\" aria-label=\"in this repository\">\n    In this repository\n  </span>\n  <span class=\"js-jump-to-badge-search-text-global d-none\" aria-label=\"in all of GitHub\">\n    All GitHub\n  </span>\n  <span aria-hidden=\"true\" class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n<div aria-hidden=\"true\" class=\"border rounded-2 flex-shrink-0 color-bg-subtle px-1 color-fg-muted ml-1 f6 d-none d-on-nav-focus js-jump-to-badge-jump\">\n  Jump to\n  <span class=\"d-inline-block ml-1 v-align-middle\">↵</span>\n</div>\n\n\n<li class=\"d-flex flex-justify-center flex-items-center p-0 f5 js-jump-to-suggestion\">\n  <svg style=\"box-sizing: content-box; color: var(--color-icon-primary);\" width=\"32\" height=\"32\" viewBox=\"0 0 16 16\" fill=\"none\" data-view-component=\"true\" class=\"m-3 anim-rotate\">\n  \n\n\n      </div>\n  </label>\n\n\n\n  <nav id=\"global-nav\" class=\"d-flex flex-column flex-md-row flex-self-stretch flex-md-self-auto\" aria-label=\"Global\">\n  <a class=\"Header-link py-md-3 d-block d-md-none py-2 border-top border-md-top-0 border-white-fade\" data-ga-click=\"Header, click, Nav menu - item:dashboard:user\" aria-label=\"Dashboard\" data-turbo=\"false\" href=\"/dashboard\">Dashboard</a>\n\n<a class=\"js-selected-navigation-item Header-link mt-md-n3 mb-md-n3 py-2 py-md-3 mr-0 mr-md-3 border-top border-md-top-0 border-white-fade\" data-hotkey=\"g p\" data-ga-click=\"Header, click, Nav menu - item:pulls context:user\" aria-label=\"Pull requests you created\" data-turbo=\"false\" data-selected-links=\"/pulls /pulls/assigned /pulls/mentioned /pulls\" href=\"/pulls\">\n    Pull<span class=\"d-inline d-md-none d-lg-inline\"> request</span>s\n Issues\n<a class=\"js-selected-navigation-item Header-link mt-md-n3 mb-md-n3 py-2 py-md-3 mr-0 mr-md-3 border-top border-md-top-0 border-white-fade d-md-none\" data-ga-click=\"Header, click, Nav menu - item:workspaces context:user\" data-turbo=\"false\" data-selected-links=\"/codespaces /codespaces\" href=\"/codespaces\">Codespaces</a>\n\n  <div class=\"d-flex position-relative\">\n    <a class=\"js-selected-navigation-item Header-link flex-auto mt-md-n3 mb-md-n3 py-2 py-md-3 mr-0 mr-md-3 border-top border-md-top-0 border-white-fade\" data-ga-click=\"Header, click, Nav menu - item:marketplace context:user\" data-octo-click=\"marketplace_click\" data-octo-dimensions=\"location:nav_bar\" data-turbo=\"false\" data-selected-links=\" /marketplace\" href=\"/marketplace\">Marketplace</a>\n  </div>\n\n<a class=\"js-selected-navigation-item Header-link mt-md-n3 mb-md-n3 py-2 py-md-3 mr-0 mr-md-3 border-top border-md-top-0 border-white-fade\" data-ga-click=\"Header, click, Nav menu - item:explore\" data-turbo=\"false\" data-selected-links=\"/explore /trending /trending/developers /integrations /integrations/feature/code /integrations/feature/collaborate /integrations/feature/ship showcases showcases_search showcases_landing /explore\" href=\"/explore\">Explore</a>\n\n\n  <a class=\"js-selected-navigation-item Header-link d-block d-md-none py-2 py-md-3 border-top border-md-top-0 border-white-fade\" data-ga-click=\"Header, click, Nav menu - item:Sponsors\" data-hydro-click=\"{&quot;event_type&quot;:&quot;sponsors.button_click&quot;,&quot;payload&quot;:{&quot;button&quot;:&quot;HEADER_SPONSORS_DASHBOARD&quot;,&quot;sponsorable_login&quot;:&quot;mrolfe&quot;,&quot;originating_url&quot;:&quot;https://github.com/mrolfe/DACSS_601_August2022_v2/blob/template/about/ProfRolfe.qmd&quot;,&quot;user_id&quot;:25716048}}\" data-hydro-click-hmac=\"b680b52981f747045218976d7cea675201e370372552c61131ce8cbf2c5930be\" data-turbo=\"false\" data-selected-links=\" /sponsors/accounts\" href=\"/sponsors/accounts\">Sponsors</a>\n\n<a class=\"Header-link d-block d-md-none mr-0 mr-md-3 py-2 py-md-3 border-top border-md-top-0 border-white-fade\" data-turbo=\"false\" href=\"/settings/profile\">Settings</a>\n\n<a class=\"Header-link d-block d-md-none mr-0 mr-md-3 py-2 py-md-3 border-top border-md-top-0 border-white-fade\" data-turbo=\"false\" href=\"/mrolfe\">\n  <img class=\"avatar avatar-user\" loading=\"lazy\" decoding=\"async\" src=\"https://avatars.githubusercontent.com/u/25716048?s=40&amp;v=4\" width=\"20\" height=\"20\" alt=\"@mrolfe\" />\n  mrolfe\n \n\n\n     Sign out \n\n\n\n\n    <a\nclass=“Header-link” href=“https://github.com/” data-hotkey=“g d” aria-label=“Homepage” data-turbo=“false” data-analytics-event=“{”category\":\"Header\",\"action\":\"go to dashboard\",\"label\":\"icon:logo\"}” >    \n</div>\n\n<div class=\"Header-item mr-0 mr-md-3 flex-order-1 flex-md-order-none\">\n    \n\n\n<span\n  data-target=\"notification-indicator.badge\"\n  class=\"mail-status unread\" >\n</span>\n\n  <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-bell\">\n<path d=\"M8 16a2 2 0 001.985-1.75c.017-.137-.097-.25-.235-.25h-3.5c-.138 0-.252.113-.235.25A2 2 0 008 16z\"></path><path fill-rule=\"evenodd\" d=\"M8 1.5A3.5 3.5 0 004.5 5v2.947c0 .346-.102.683-.294.97l-1.703 2.556a.018.018 0 00-.003.01l.001.006c0 .002.002.004.004.006a.017.017 0 00.006.004l.007.001h10.964l.007-.001a.016.016 0 00.006-.004.016.016 0 00.004-.006l.001-.007a.017.017 0 00-.003-.01l-1.703-2.554a1.75 1.75 0 01-.294-.97V5A3.5 3.5 0 008 1.5zM3 5a5 5 0 0110 0v2.947c0 .05.015.098.042.139l1.703 2.555A1.518 1.518 0 0113.482 13H2.518a1.518 1.518 0 01-1.263-2.36l1.703-2.554A.25.25 0 003 7.947V5z\"></path>\n\n\n\n</div>\n\n\n<div class=\"Header-item position-relative d-none d-md-flex\">\n    <details class=\"details-overlay details-reset\">\n\n\n\n\n\n\n\n New repository \n Import repository \n New gist \n New organization \n\n\n</div>\n\n<div class=\"Header-item position-relative mr-0 d-none d-md-flex\">\n    \n\n\n  \n\n \n\n\n \n\n\n    <p class=\"ml-1 mb-2 mt-2 color-fg-default\" data-show-on-error>\n      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-alert\">\n<path fill-rule=\"evenodd\" d=\"M8.22 1.754a.25.25 0 00-.44 0L1.698 13.132a.25.25 0 00.22.368h12.164a.25.25 0 00.22-.368L8.22 1.754zm-1.763-.707c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0114.082 15H1.918a1.75 1.75 0 01-1.543-2.575L6.457 1.047zM9 11a1 1 0 11-2 0 1 1 0 012 0zm-.25-5.25a.75.75 0 00-1.5 0v2.5a.75.75 0 001.5 0v-2.5z\"></path>\n\n      Sorry, something went wrong.\n    </p>\n  </include-fragment>\n\n\n</div>\n\n</div>\n\n\n\n<div data-pjax-replace id=\"js-flash-container\" data-turbo-replace>\n\n\n\n<details\nclass=“details-reset details-overlay details-overlay-dark js-command-palette-dialog” data-pjax-replace id=“command-palette-pjax-container” data-turbo-replace >\n\n\n \n  <command-palette-mode\n      data-char=\"#\"\n        data-scope-types=\"[&quot;&quot;]\"\n        data-placeholder=\"Search issues and pull requests\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"#\"\n        data-scope-types=\"[&quot;owner&quot;,&quot;repository&quot;]\"\n        data-placeholder=\"Search issues, pull requests, discussions, and projects\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"!\"\n        data-scope-types=\"[&quot;owner&quot;,&quot;repository&quot;]\"\n        data-placeholder=\"Search projects\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"@\"\n        data-scope-types=\"[&quot;&quot;]\"\n        data-placeholder=\"Search or jump to a user, organization, or repository\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"@\"\n        data-scope-types=\"[&quot;owner&quot;]\"\n        data-placeholder=\"Search or jump to a repository\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"/\"\n        data-scope-types=\"[&quot;repository&quot;]\"\n        data-placeholder=\"Search files\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"?\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"&gt;\"\n        data-placeholder=\"Run a command\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"\"\n        data-scope-types=\"[&quot;&quot;]\"\n        data-placeholder=\"Search or jump to...\"\n    ></command-palette-mode>\n    <command-palette-mode\n      data-char=\"\"\n        data-scope-types=\"[&quot;owner&quot;]\"\n        data-placeholder=\"Search or jump to...\"\n    ></command-palette-mode>\n  <command-palette-mode\n    class=\"js-command-palette-default-mode\"\n    data-char=\"\"\n    data-placeholder=\"Search or jump to...\"\n  ></command-palette-mode>\n\n  <command-palette-input placeholder=\"Search or jump to...\"\n\n    data-action=\"\n      command-palette-input:command-palette#onInput\n      command-palette-select:command-palette#onSelect\n      command-palette-descope:command-palette#onDescope\n      command-palette-cleared:command-palette#onInputClear\n    \"\n  >\n    <div class=\"js-search-icon d-flex flex-items-center mr-2\" style=\"height: 26px\">\n      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-search color-fg-muted\">\n<path fill-rule=\"evenodd\" d=\"M11.5 7a4.499 4.499 0 11-8.998 0A4.499 4.499 0 0111.5 7zm-.82 4.74a6 6 0 111.06-1.06l3.04 3.04a.75.75 0 11-1.06 1.06l-3.04-3.04z\"></path>\n\n  </div>\n    <div class=\"js-spinner d-flex flex-items-center mr-2 color-fg-muted\" hidden>\n      <svg aria-label=\"Loading\" class=\"anim-rotate\" viewBox=\"0 0 16 16\" fill=\"none\" width=\"16\" height=\"16\">\n        <circle\n          cx=\"8\"\n          cy=\"8\"\n          r=\"7\"\n          stroke=\"currentColor\"\n          stroke-opacity=\"0.25\"\n          stroke-width=\"2\"\n          vector-effect=\"non-scaling-stroke\"\n        ></circle>\n        <path\n          d=\"M15 8a7.002 7.002 0 00-7-7\"\n          stroke=\"currentColor\"\n          stroke-width=\"2\"\n          stroke-linecap=\"round\"\n          vector-effect=\"non-scaling-stroke\"\n        ></path>\n      </svg>\n    </div>\n    <command-palette-scope >\n      <div data-target=\"command-palette-scope.placeholder\" hidden class=\"color-fg-subtle\">/&nbsp;&nbsp;<span class=\"text-semibold color-fg-default\">...</span>&nbsp;&nbsp;/&nbsp;&nbsp;</div>\n          <command-palette-token\n            data-text=\"mrolfe\"\n            data-id=\"MDQ6VXNlcjI1NzE2MDQ4\"\n            data-type=\"owner\"\n            data-value=\"mrolfe\"\n            data-targets=\"command-palette-scope.tokens\"\n            class=\"color-fg-default text-semibold\"\n            style=\"white-space:nowrap;line-height:20px;\"\n            >mrolfe<span class=\"color-fg-subtle text-normal\">&nbsp;&nbsp;/&nbsp;&nbsp;</span></command-palette-token>\n          <command-palette-token\n            data-text=\"DACSS_601_August2022_v2\"\n            data-id=\"R_kgDOH2-J2w\"\n            data-type=\"repository\"\n            data-value=\"DACSS_601_August2022_v2\"\n            data-targets=\"command-palette-scope.tokens\"\n            class=\"color-fg-default text-semibold\"\n            style=\"white-space:nowrap;line-height:20px;\"\n            >DACSS_601_August2...<span class=\"color-fg-subtle text-normal\">&nbsp;&nbsp;/&nbsp;&nbsp;</span></command-palette-token>\n    </command-palette-scope>\n    <div class=\"command-palette-input-group flex-1 form-control border-0 box-shadow-none\" style=\"z-index: 0\">\n      <div class=\"command-palette-typeahead position-absolute d-flex flex-items-center Truncate\">\n        <span class=\"typeahead-segment input-mirror\" data-target=\"command-palette-input.mirror\"></span>\n        <span class=\"Truncate-text\" data-target=\"command-palette-input.typeaheadText\"></span>\n        <span class=\"typeahead-segment\" data-target=\"command-palette-input.typeaheadPlaceholder\"></span>\n      </div>\n      <input\n        class=\"js-overlay-input typeahead-input d-none\"\n        disabled\n        tabindex=\"-1\"\n        aria-label=\"Hidden input for typeahead\"\n      >\n      <input\n        type=\"text\"\n        autocomplete=\"off\"\n        autocorrect=\"off\"\n        autocapitalize=\"off\"\n        spellcheck=\"false\"\n        class=\"js-input typeahead-input form-control border-0 box-shadow-none input-block width-full no-focus-indicator\"\n        aria-label=\"Command palette input\"\n        aria-haspopup=\"listbox\"\n        aria-expanded=\"false\"\n        aria-autocomplete=\"list\"\n        aria-controls=\"command-palette-page-stack\"\n        role=\"combobox\"\n        data-action=\"\n          input:command-palette-input#onInput\n          keydown:command-palette-input#onKeydown\n        \"\n      >\n    </div>\n        <div data-view-component=\"true\" class=\"position-relative d-inline-block\">\n<button aria-keyshortcuts=\"Meta+Delete\" data-action=\"click:command-palette-input#onClear keypress:command-palette-input#onClear\" data-target=\"command-palette-input.clearButton\" id=\"command-palette-clear-button\" hidden=\"hidden\" type=\"button\" data-view-component=\"true\" class=\"btn-octicon command-palette-input-clear-button\">      <svg aria-hidden=\"true\" height=\"16\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" data-view-component=\"true\" class=\"octicon octicon-x-circle-fill\">\n<path fill-rule=\"evenodd\" d=\"M2.343 13.657A8 8 0 1113.657 2.343 8 8 0 012.343 13.657zM6.03 4.97a.75.75 0 00-1.06 1.06L6.94 8 4.97 9.97a.75.75 0 101.06 1.06L8 9.06l1.97 1.97a.75.75 0 101.06-1.06L9.06 8l1.97-1.97a.75.75 0 10-1.06-1.06L8 6.94 6.03 4.97z\"></path>\n\n\nClear Command Palette"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DACSS 601: Data Science Fundamentals Fall-2022",
    "section": "",
    "text": "Challenge 2 Solutions\n\n\n\n\n\n\n\nchallenge_2\n\n\nsolution\n\n\nrailroad\n\n\nfaostat\n\n\nhotel_bookings\n\n\n\n\nData wrangling: using group() and summarise()\n\n\n\n\n\n\nSep 21, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 2 Instructions\n\n\n\n\n\n\n\nchallenge_2\n\n\ninstructions\n\n\nrailroads\n\n\nfaostat\n\n\nhotel_bookings\n\n\n\n\nData wrangling: using group() and summarise()\n\n\n\n\n\n\nSep 14, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 1 Instructions\n\n\n\n\n\n\n\nchallenge_1\n\n\ninstructions\n\n\nrailroads\n\n\nfaostat\n\n\nwildbirds\n\n\n\n\nReading in data and creating a post\n\n\n\n\n\n\nSep 1, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 8 Instructions\n\n\n\n\n\n\n\nchallenge_8\n\n\nrailroads\n\n\nsnl\n\n\nfaostat\n\n\ndebt\n\n\n\n\nJoining Data\n\n\n\n\n\n\nAug 25, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 7 Instructions\n\n\n\n\n\n\n\nchallenge_7\n\n\nhotel_bookings\n\n\naustralian_marriage\n\n\nair_bnb\n\n\neggs\n\n\nabc_poll\n\n\nfaostat\n\n\nus_hh\n\n\n\n\nVisualizing Multiple Dimensions\n\n\n\n\n\n\nAug 24, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 6 Instructions\n\n\n\n\n\n\n\nchallenge_6\n\n\nhotel_bookings\n\n\nair_bnb\n\n\nfed_rate\n\n\ndebt\n\n\nusa_hh\n\n\nabc_poll\n\n\n\n\nVisualizing Time and Relationships\n\n\n\n\n\n\nAug 23, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 5 Instructions\n\n\n\n\n\n\n\nchallenge_5\n\n\nrailroads\n\n\ncereal\n\n\nair_bnb\n\n\npathogen_cost\n\n\naustralian_marriage\n\n\npublic_schools\n\n\nusa_hh\n\n\n\n\nIntroduction to Visualization\n\n\n\n\n\n\nAug 22, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 4 Instructions\n\n\n\n\n\n\n\nchallenge_4\n\n\n\n\nMore data wrangling: mutate\n\n\n\n\n\n\nAug 18, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge 3 Instructions\n\n\n\n\n\n\n\nchallenge_3\n\n\n\n\nTidy Data: Pivoting\n\n\n\n\n\n\nAug 17, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\n  \n\n\n\n\nChallenge 1 Solution\n\n\n\n\n\n\n\nchallenge_1\n\n\nsolution\n\n\n\n\nReading in data and creating a post\n\n\n\n\n\n\nAug 16, 2022\n\n\nMeredith Rolfe\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Contributors",
    "section": "",
    "text": "No matching items"
  }
]